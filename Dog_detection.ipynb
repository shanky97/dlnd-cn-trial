{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用神经网络来预测图像是狗狗概率\n",
    "\n",
    "本项目使用了一个经过预处理后较小的数据集，数据集中仅含有图像的特征结果。对于如何获取图像的特征，这里附上了open cv中对于图像特征的说明。\n",
    "http://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_feature2d/py_features_meaning/py_features_meaning.html\n",
    "\n",
    "\n",
    "在该 notebook 中，我们基于以下三个特征来了解图像是狗狗的概率：\n",
    "\n",
    "- Feature1\n",
    "- Feature2\n",
    "- Feature3\n",
    "\n",
    "图像是否是狗狗，通过0，1来表示；\n",
    "每一行代表一个图像，第一列：是否是狗狗；第二至第四列：feature1-3；\n",
    "\n",
    "## 加载数据\n",
    "\n",
    "为了加载数据并很好地进行格式化，我们将使用两个非常有用的包，即 Pandas 和 Numpy。 你可以在这里阅读文档：\n",
    "\n",
    "- https://pandas.pydata.org/pandas-docs/stable/\n",
    "- https://docs.scipy.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing pandas and numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Reading the csv file into a pandas DataFrame\n",
    "data = pd.read_csv('dog_data.csv')\n",
    "\n",
    "# Printing out the first 10 rows of our data\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制数据\n",
    "\n",
    "\n",
    "首先让我们对数据进行绘图，看看它是什么样的。为了绘制二维图，让我们先忽略feature3。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to help us plot\n",
    "def plot_points(data):\n",
    "    X = np.array(data[[\"feature1\",\"feature2\"]])\n",
    "    y = np.array(data[\"dog\"])\n",
    "    admitted = X[np.argwhere(y==1)]\n",
    "    rejected = X[np.argwhere(y==0)]\n",
    "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'red', edgecolor = 'k')\n",
    "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'cyan', edgecolor = 'k')\n",
    "    plt.xlabel('Feature_1')\n",
    "    plt.ylabel('Feature_2')\n",
    "    \n",
    "# Plotting the points\n",
    "plot_points(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "粗略来说，这两个feature并没有很好地分离图像是不是狗狗。 也许将feature3考虑进来会有帮助？ \n",
    "接下来我们将绘制 4 个图，每个图代表一个级别。\n",
    "因为feature3是离散型数据，每个图像的feature3为[1,2,3,4]中的一个数字，这里用Rank（等级）表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the ranks\n",
    "data_rank1 = data[data[\"feature3\"]==1]\n",
    "data_rank2 = data[data[\"feature3\"]==2]\n",
    "data_rank3 = data[data[\"feature3\"]==3]\n",
    "data_rank4 = data[data[\"feature3\"]==4]\n",
    "\n",
    "# Plotting the graphs\n",
    "plot_points(data_rank1)\n",
    "plt.title(\"Rank 1\")\n",
    "plt.show()\n",
    "plot_points(data_rank2)\n",
    "plt.title(\"Rank 2\")\n",
    "plt.show()\n",
    "plot_points(data_rank3)\n",
    "plt.title(\"Rank 3\")\n",
    "plt.show()\n",
    "plot_points(data_rank4)\n",
    "plt.title(\"Rank 4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在看起，等级越高，图像是狗狗的概率越高。 让我们使用评级 (rank) 作为我们的输入之一。 为了做到这一点，我们应该对它进行一次one-hot 编码。\n",
    "\n",
    "## 任务1: 将feature3进行 One-hot 编码\n",
    "我们将在 Pandas 中使用 `get_dummies` 函数，根据todo的提示完成任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:  Make dummy variables for rank\n",
    "one_hot_data = None\n",
    "\n",
    "# TODO: Drop the previous rank column\n",
    "one_hot_data = None\n",
    "\n",
    "# Print the first 10 rows of our data\n",
    "one_hot_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务2: 数据的标准化\n",
    "\n",
    "下一步是缩放数据。 我们注意到feature2的范围是 1.0-4.0，而feature1的范围大概是 200-800，这个范围要大得多。 这意味着我们的数据存在偏差，使得神经网络很难处理。 让我们将两个特征放在 0-1 的范围内，将feature2除以 4.0，将feature1除以 800。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a copy of our data\n",
    "processed_data = one_hot_data[:]\n",
    "\n",
    "# TODO: Scale the columns\n",
    "processed_data['feature1'] = None\n",
    "processed_data['feature2'] = None\n",
    "\n",
    "# Printing the first 10 rows of our procesed data\n",
    "processed_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务3: 将数据分成训练集和测试集\n",
    "\n",
    "为了测试我们的算法，我们将数据分为训练集和测试集。 测试集的大小将占总数据的 10％。\n",
    "可以使用numpy中的random choice函数来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: separate dataset into train and test dataset, 10% of which is test dataset\n",
    "\n",
    "\n",
    "\n",
    "print(\"Number of training samples is\", len(train_data))\n",
    "print(\"Number of testing samples is\", len(test_data))\n",
    "print(train_data[:10])\n",
    "print(test_data[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将数据分成特征和目标（标签）\n",
    "现在，我们将把数据分为特征 (features)（X）和目标 (targets)（y），并把这里’dog‘标签去除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_data.drop('dog', axis=1)\n",
    "targets = train_data['dog']\n",
    "features_test = test_data.drop('dog', axis=1)\n",
    "targets_test = test_data['dog']\n",
    "\n",
    "print(features[:10])\n",
    "print(targets[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 问题1-请双击文字来回答:\n",
    "\n",
    "（请查阅资料回答我们）针对一个数据集的预处理，有哪些可行的数据清洗方式？\n",
    "\n",
    "你的回答：\n",
    "\n",
    "## 问题2\n",
    "\n",
    "除了使用numpy.random.choice函数以外，还有哪些用于拆分训练集及验证集的方式？\n",
    "\n",
    "你的回答："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 任务4: 训练二层神经网络\n",
    "下列函数会训练二层神经网络。 首先，我们将写一些 helper 函数，用于函数的正向传播。\n",
    "- Sigmoid 激活函数\n",
    "\n",
    "$$\\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "- Sigmoid函数导数\n",
    "\n",
    "$$\\sigma'(x) = \\sigma(x) * (1 - \\sigma(x))$$\n",
    "\n",
    "- 误差函数\n",
    "\n",
    "$$Error(y, \\hat{y}) = - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Activation (sigmoid) function\n",
    "def sigmoid(x):\n",
    "    return None\n",
    "\n",
    "def sigmoid_prime(x):\n",
    "    return None\n",
    "\n",
    "def error_formula(y, output):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务5: 误差反向传播\n",
    "\n",
    "现在轮到误差项的编写。 记住这是由方程 $$ -(y-\\hat{y}) \\sigma'(x) $$ 给出的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write the error term formula\n",
    "def error_term_formula(y, output):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务6:编写权重更新函数的神经网络训练模型\n",
    "\n",
    "之前已经把神经网络传播需要的函数都编写好了，下面来写我们最重要的神经网络更新函数吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_nn(features, targets, epochs, learnrate):\n",
    "    \n",
    "    # Use to same seed to make debugging easier\n",
    "    np.random.seed(42)\n",
    "\n",
    "    n_records, n_features = features.shape\n",
    "    last_loss = None\n",
    "\n",
    "    # Initialize weights\n",
    "    weights = np.random.normal(scale=1 / n_features**.5, size=n_features)\n",
    "\n",
    "    for e in range(epochs):\n",
    "        del_w = np.zeros(weights.shape)\n",
    "        for x, y in zip(features.values, targets):\n",
    "            # Loop through all records, x is the input, y is the target\n",
    "\n",
    "            # TODO: forward Propagation\n",
    "            # Activation of the output unit\n",
    "            #   Notice we multiply the inputs and the weights here \n",
    "            #   rather than storing h as a separate variable \n",
    "            output = None\n",
    "\n",
    "            # TODO: The error, the target minus the network output\n",
    "            error = None\n",
    "            \n",
    "            # TODO:  Backward Propagation\n",
    "            # The error term\n",
    "            error_term = None\n",
    "\n",
    "            # TODO: The gradient descent step, the error times the gradient times the inputs\n",
    "            del_w += None\n",
    "\n",
    "        # TODO: Update the weights here. The learning rate times the \n",
    "        # change in weights, divided by the number of records to average\n",
    "        weights = None\n",
    "\n",
    "        # Printing out the mean square error on the training set\n",
    "        if e % (epochs / 10) == 0:\n",
    "            \n",
    "            # TODO: get model output\n",
    "            out = None\n",
    "            \n",
    "            # TODO: get least square loss \n",
    "            loss = None\n",
    "            \n",
    "            print(\"Epoch:\", e)\n",
    "            \n",
    "            # TODO: set last_loss = loss of previous iteration\n",
    "            # compare last_loss and loss\n",
    "            # if loss > last_loss, then print 'WARNING!- Loss Increasing'\n",
    "            if :\n",
    "                None\n",
    "            else :\n",
    "                None\n",
    "    print(\"Finished training!\")\n",
    "    return weights\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务7: 调整参数来训练训练你的网络\n",
    "\n",
    "在这里，你可以调整你的epochs以及learnrate来提高你的网络预测精度\n",
    "\n",
    "# （可选任务）：绘制你的loss曲线来查看合适的参数设置\n",
    "\n",
    "通过修改train_nn函数来输出你的loss值变化，判断参数设置的修改方案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: SET Neural Network hyperparameters\n",
    "epochs = None\n",
    "learnrate = None\n",
    "weights = train_nn(features, targets, epochs, learnrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务8: 计算测试 (Test) 数据的精确度\n",
    "\n",
    "由于我们这个模型用于预测狗狗是图像的可能性，结果为二分法。\n",
    "因此，我们使用model输出是否大于0.5来判断模型的预测结果是不是狗狗。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate accuracy on test data\n",
    "tes_out = None\n",
    "predictions = None\n",
    "accuracy = None\n",
    "print(\"Prediction accuracy: {:.3f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 有趣的狗狗图像\n",
    "\n",
    "恭喜你！经过上面的神经网络训练，我们已经得到一个可以估计狗狗的网络了！\n",
    "\n",
    "下面就演示如何使用一个神经网络来估算图像中狗狗的位置，在这里我们要使用一个卷积神经网络，以及一个已经训练好的结果。我们会在正式的课程里面详细给大家介绍卷积神经网络是如何使用的（可选课程）。\n",
    "\n",
    "这里简单解释一下：\n",
    "- 卷积神经网络会在图像中提取特征\n",
    "- 训练好的网络会将图像特征分类为具体的物体\n",
    "\n",
    "因此使用卷积神经网络提取特征之后，直接使用训练好的网络来得到分类物体就能得到如下的分类结果。很酷炫吧！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ResNet_CAM import *\n",
    "import glob\n",
    "\n",
    "lists = glob.glob('images/*.png')\n",
    "\n",
    "# TODO: Upload your image or pick up any image in the folder 'images/xx.png'\n",
    "for img_path in lists:\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2)\n",
    "    CAM = plot_CAM(img_path,ax1,ax2,fig)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
